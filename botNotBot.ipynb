{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['twitter_gender.csv.zip',\n",
       " 'toPush',\n",
       " '.DS_Store',\n",
       " 'maleOrFemale.ipynb',\n",
       " 'maleOrFemalet_loadAndFIlter_es.ipynb',\n",
       " 'botNotBot.ipynb',\n",
       " '02.CNN_100x50x300D_google_0.9693.h5',\n",
       " 'dataGeneration-es.py',\n",
       " 'dataGeneration.py',\n",
       " 'matrixTweetsEmb_ALT.dump',\n",
       " 'Untitled.ipynb',\n",
       " 'matrixTweetsEmb_FAST2.dump',\n",
       " 'google_w2v_300.bin',\n",
       " 'botNotBot.py',\n",
       " 'botNotBot_es.ipynb',\n",
       " 'gender-classifier-DFE-791531.csv',\n",
       " 'botOrNot_loadAndFIlter_es.ipynb',\n",
       " 'maleOrFemal_es.ipynb',\n",
       " '01.weights.04-0.48041_0.8479.fasttext_female_male.hdf5',\n",
       " '02.CNN_100x50x300D_google_0.98.h5',\n",
       " 'male_es.txt',\n",
       " 'createMaleFemale_new_examples.py',\n",
       " 'Dataset-README',\n",
       " 'botOrNot_loadAndFIlter.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " '01.CNN_100x50x300D_google_0.964.h5',\n",
       " 'en',\n",
       " 'cpa.py',\n",
       " '.git',\n",
       " 'listaClasses.dump',\n",
       " 'maleOrFemalet_loadAndFIlter.ipynb',\n",
       " 'female_es.txt',\n",
       " '.idea']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathEn = \"/Users/kram/Downloads/botOrNot-en_es/en\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we will create a procedure to be tested on a single file.\n",
    "\n",
    "After this first step will be completed, we will extend this procedure to create a complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile = \"/Users/kram/Downloads/botOrNot-en_es/en/1a5b808546838869bc39cebdbad951e3.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import io\n",
    "\n",
    "def iter_docs(author):\n",
    "    '''This function extracts the text and the language from the XML'''\n",
    "    author_attr = author.attrib\n",
    "    for doc in author.iter('document'):\n",
    "        doc_dict = author_attr.copy()\n",
    "        doc_dict.update(doc.attrib)\n",
    "        doc_dict['data'] = doc.text\n",
    "        yield doc_dict\n",
    "\n",
    "xml_data = open(testfile, \"r\") # Opening the text file\n",
    "etree = ET.parse(xml_data) # Create an ElementTree object \n",
    "df = pd.DataFrame(list(iter_docs(etree.getroot()))) #Append the info to a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1:7 Wherefore she went after their families: o...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And he put his hand over the host: and they ga...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65:18 But be ye far from the Philistines.</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4:29 And rose up, and went out.</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24:13 My son, keep my mouth hath spoken, sayin...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30:21 And afterwards she bare unto him.</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>And on the ground, and took Rebekah, and said ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13:10 And I the LORD came unto Elim: and in th...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>And his servants for his issue.</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20:3 And cast him down: deliver my people shal...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data lang\n",
       "0  1:7 Wherefore she went after their families: o...   en\n",
       "1  And he put his hand over the host: and they ga...   en\n",
       "2          65:18 But be ye far from the Philistines.   en\n",
       "3                    4:29 And rose up, and went out.   en\n",
       "4  24:13 My son, keep my mouth hath spoken, sayin...   en\n",
       "5            30:21 And afterwards she bare unto him.   en\n",
       "6  And on the ground, and took Rebekah, and said ...   en\n",
       "7  13:10 And I the LORD came unto Elim: and in th...   en\n",
       "8                    And his servants for his issue.   en\n",
       "9  20:3 And cast him down: deliver my people shal...   en"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1:7 Wherefore she went after their families: of Sered, the family of the priests, and the light shine upon thy head; for I fear the LORD.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting ID to insert in the dataframe\n",
    "\n",
    "filename = testfile.split(\"/\")[-1].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1a5b808546838869bc39cebdbad951e3'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now try to extend the procedure to the full directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total running time is 129.99335503578186\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Creating empty dataframe\n",
    "dataEn = pd.DataFrame()\n",
    "\n",
    "# Monitoring time to load the files\n",
    "start = time.time()\n",
    "\n",
    "for root, dirs, files in os.walk(pathEn):\n",
    "    for file in files:\n",
    "        if file == 'truth.txt':\n",
    "            continue\n",
    "        else: \n",
    "            try:\n",
    "                pathToFile = root + '/' + file # Creating path\n",
    "                # print(pathToFile) # Just for debugging\n",
    "                xml_data = open(pathToFile, \"r\", encoding=\"utf8\") # Opening the text file\n",
    "                etree = ET.parse(xml_data) # Create an ElementTree object\n",
    "                data = list(iter_docs(etree.getroot())) # Create a list of dictionaries with the data\n",
    "                filename = file.split(\".\")[0] # Get filename\n",
    "                for dictionary in data: # Loop through the dictionary\n",
    "                    dictionary['ID'] = filename # Append filename\n",
    "                dataEn = dataEn.append(data)  # Append the list of dictionary to a pandas dataframe\n",
    "                \n",
    "            # If the file is not valid, skip it\n",
    "            except ValueError as e:\n",
    "                print(e)\n",
    "                continue\n",
    "            \n",
    "end = time.time()\n",
    "print(\"Total running time is\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>data</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>867be96f95dfc4e24541d19c6a5ab8bf</td>\n",
       "      <td>Alex is too nice for love island :(</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>867be96f95dfc4e24541d19c6a5ab8bf</td>\n",
       "      <td>RT @STVNews: Teenager charged with rape of wom...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>867be96f95dfc4e24541d19c6a5ab8bf</td>\n",
       "      <td>@LipsTaco @jennyhastie</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>867be96f95dfc4e24541d19c6a5ab8bf</td>\n",
       "      <td>@RyanDunbar8 happy bday Ryan have the best day...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>867be96f95dfc4e24541d19c6a5ab8bf</td>\n",
       "      <td>@jennyhastie @bootywhispers I just wanna let j...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>867be96f95dfc4e24541d19c6a5ab8bf</td>\n",
       "      <td>@bootywhispers @jennyhastie what would u do ?</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>867be96f95dfc4e24541d19c6a5ab8bf</td>\n",
       "      <td>@Aidsterrr Asking for a mate :/ wee bit line o...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>867be96f95dfc4e24541d19c6a5ab8bf</td>\n",
       "      <td>Wonder what a Sunday without the fear feels like</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>867be96f95dfc4e24541d19c6a5ab8bf</td>\n",
       "      <td>RT @liamfrenchx: Brutal getn wee flashbacks a ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>867be96f95dfc4e24541d19c6a5ab8bf</td>\n",
       "      <td>Went to a&amp;amp;e last night myself after I lock...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ID  \\\n",
       "0  867be96f95dfc4e24541d19c6a5ab8bf   \n",
       "1  867be96f95dfc4e24541d19c6a5ab8bf   \n",
       "2  867be96f95dfc4e24541d19c6a5ab8bf   \n",
       "3  867be96f95dfc4e24541d19c6a5ab8bf   \n",
       "4  867be96f95dfc4e24541d19c6a5ab8bf   \n",
       "5  867be96f95dfc4e24541d19c6a5ab8bf   \n",
       "6  867be96f95dfc4e24541d19c6a5ab8bf   \n",
       "7  867be96f95dfc4e24541d19c6a5ab8bf   \n",
       "8  867be96f95dfc4e24541d19c6a5ab8bf   \n",
       "9  867be96f95dfc4e24541d19c6a5ab8bf   \n",
       "\n",
       "                                                data lang  \n",
       "0                Alex is too nice for love island :(   en  \n",
       "1  RT @STVNews: Teenager charged with rape of wom...   en  \n",
       "2                             @LipsTaco @jennyhastie   en  \n",
       "3  @RyanDunbar8 happy bday Ryan have the best day...   en  \n",
       "4  @jennyhastie @bootywhispers I just wanna let j...   en  \n",
       "5      @bootywhispers @jennyhastie what would u do ?   en  \n",
       "6  @Aidsterrr Asking for a mate :/ wee bit line o...   en  \n",
       "7   Wonder what a Sunday without the fear feels like   en  \n",
       "8  RT @liamfrenchx: Brutal getn wee flashbacks a ...   en  \n",
       "9  Went to a&amp;e last night myself after I lock...   en  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataEn.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  Alex is too nice for love island :(\n",
       "0    RT @AlexanderRugaev: The Crypto Finance Ecosys...\n",
       "0    Check out these awesome cooking t-shirts &amp;...\n",
       "0    YEWWinfo Tiny Nanoparticles to Treat a Huge Pr...\n",
       "0    Sr. Project Manager Water / Wastewater Enginee...\n",
       "0                      @lolzdonz @beckyfrancesxo !!!!!\n",
       "0    @jennycastle96 Ahaha last time acting reckless 😂😂\n",
       "0    Apr. 20/2002 - The brodway show Jesus Christ S...\n",
       "0    I'm so excited for the boojum I'm about to get...\n",
       "0    Killer bonus here 70+ page free download to he...\n",
       "0                        boooo https://t.co/Q32Ttd9FIH\n",
       "0    Create a life you love.\\n\\n#quote #life https:...\n",
       "0    @puretemerity The archaeology on Arran is amaz...\n",
       "0    Why Silicon Valley can’t fix itself\\n\\nhttps:/...\n",
       "0    @PayChen @designtaxi So you have place to put ...\n",
       "0    #GameofThrones #ThorosofMyr: There's no story....\n",
       "0    the amount of pride flags he has around him, a...\n",
       "0    @mike_mcgrail Pretty sure I seen your doppelga...\n",
       "0        Most games are lost, not won! - Casey Stengel\n",
       "0       a person wearing a hat https://t.co/UqHgJy7ji7\n",
       "0    Why the ‘Manhattan Madam’ Is Ensnared in the M...\n",
       "0    Probably going to visit the folks in T.O. in t...\n",
       "0    I painted \"Easy-going Alexander Fleming\" after...\n",
       "0    Check out this Big-Dog Pet Fountain - Keeps Fr...\n",
       "0    Just commented on @thejournal_ie: Poll: Did yo...\n",
       "0    RT @jonathansteel: Speaker from @SatAppsCatapu...\n",
       "0    Then I ran out of our database, so we rooted y...\n",
       "0    The cause of spiritual life for the spirituall...\n",
       "0    There's A New \"Deadpool 2\" Trailer And Holy He...\n",
       "0             © @5sosupdateww ] https//tco/1ukhqdtduy.\n",
       "                           ...                        \n",
       "0    RT @IainGAnderson: Glad you were able to visit...\n",
       "0    Mad how birds throw on a pair of them fake gla...\n",
       "0    Why isn't @Target's #grocery offering helping ...\n",
       "0    All arguments have two sides, but some have no...\n",
       "0    A game where you must clear out a strange test...\n",
       "0    RT @JoParkerBear: I love that rightwingers say...\n",
       "0    #goodluc….. actor... an actor. rt @xxkissmeyou...\n",
       "0    Jeffrey Tambor Is Not Returning To \"Transparen...\n",
       "0    @BerthanPete @IsThisAB0t Can't see this being ...\n",
       "0    @JohnRMoffitt I thought the trump base didn't ...\n",
       "0    In fact I would go as far to say that it’s act...\n",
       "0    Warmer Arctic temperatures are the 'new normal...\n",
       "0    On her first day back from her honeymoon, @Ste...\n",
       "0    RT @TabithaKhaye: What defines us is how well ...\n",
       "0    Excited to be able to start another season. I ...\n",
       "0    RT @MeredithFrost: Best thing you’ll see today...\n",
       "0    RT por MAS SEGUIDORES: Da RT RT SÍGUEME\\ny SIG...\n",
       "0    Senior Software Engineer Frontend – Loan Servi...\n",
       "0    I change my mind...puff-puff-give. Last candid...\n",
       "0    RT @Internet_SF: \"Member States have failed to...\n",
       "0    @Kezzang69 I can hear the Black Bull jukey cal...\n",
       "0    Here's a look at the top 2018 strategic IT bud...\n",
       "0    What you don't know won't hurt you but it prov...\n",
       "0        @CostaCoffee @moto Not been picked up yet! :(\n",
       "0    New at Affiliate Marketing?  How to Start Off ...\n",
       "0    You should check this site out if you want 117...\n",
       "0    This tweet was sent via Twitter for iPhone. I ...\n",
       "0    RT @1dish4theroad: The history of #London is r...\n",
       "0    12 Great Motivational Quotes here: http://t.co...\n",
       "0                        I think i'm going to YOLO it.\n",
       "Name: data, Length: 4120, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataEn['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>data</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>412000</td>\n",
       "      <td>412000</td>\n",
       "      <td>412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4120</td>\n",
       "      <td>373908</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>61d95a1f860bc9a7381ae76bf9a798af</td>\n",
       "      <td>wow, it's so sad about MJ :(</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>100</td>\n",
       "      <td>136</td>\n",
       "      <td>412000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      ID                          data    lang\n",
       "count                             412000                        412000  412000\n",
       "unique                              4120                        373908       1\n",
       "top     61d95a1f860bc9a7381ae76bf9a798af  wow, it's so sad about MJ :(      en\n",
       "freq                                 100                           136  412000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataEn.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have merged the IDs with the data, we can create another dataframe with the labels and then merge them using the ID as key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathToLabels = \"/Users/kram/Downloads/botOrNot-en_es/en/truth.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kram/anaconda3/envs/EmoContext/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "target = pd.read_csv(pathToLabels, sep=\":::\")\n",
    "target.columns=['ID', 'botOrHuman', 'sex'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>botOrHuman</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2bed15d46872169dc7deaf8d2b43a56</td>\n",
       "      <td>bot</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25395a7dbd2caa3d828bb3dbd57d8857</td>\n",
       "      <td>bot</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1c9f161414334b286c4dc70163744390</td>\n",
       "      <td>bot</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1da1f87b3dc778f28268eec70ce94f19</td>\n",
       "      <td>bot</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bd4286bfafb8a35b8e132a396b884e07</td>\n",
       "      <td>bot</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>af61c4c017f246da69285497baf3dc0b</td>\n",
       "      <td>bot</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7a36090b20e7bddbe55561c52f959041</td>\n",
       "      <td>bot</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5183ff5bedcab9a6a301ff04e27166cd</td>\n",
       "      <td>bot</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6ac10734f35a773e9f2209f8668fffdf</td>\n",
       "      <td>bot</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b5b06752b42d3c354cc8e126f030a864</td>\n",
       "      <td>bot</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ID botOrHuman  sex\n",
       "0   2bed15d46872169dc7deaf8d2b43a56        bot  bot\n",
       "1  25395a7dbd2caa3d828bb3dbd57d8857        bot  bot\n",
       "2  1c9f161414334b286c4dc70163744390        bot  bot\n",
       "3  1da1f87b3dc778f28268eec70ce94f19        bot  bot\n",
       "4  bd4286bfafb8a35b8e132a396b884e07        bot  bot\n",
       "5  af61c4c017f246da69285497baf3dc0b        bot  bot\n",
       "6  7a36090b20e7bddbe55561c52f959041        bot  bot\n",
       "7  5183ff5bedcab9a6a301ff04e27166cd        bot  bot\n",
       "8  6ac10734f35a773e9f2209f8668fffdf        bot  bot\n",
       "9  b5b06752b42d3c354cc8e126f030a864        bot  bot"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>botOrHuman</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4119</td>\n",
       "      <td>4119</td>\n",
       "      <td>4119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4119</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>8f2c2cf696f60fb8ec4747771d4f0fc7</td>\n",
       "      <td>human</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2060</td>\n",
       "      <td>2059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      ID botOrHuman   sex\n",
       "count                               4119       4119  4119\n",
       "unique                              4119          2     3\n",
       "top     8f2c2cf696f60fb8ec4747771d4f0fc7      human   bot\n",
       "freq                                   1       2060  2059"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now proceed with the concatenation of the dataframes for the English language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedEnData = pd.merge(dataEn, target, on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>data</th>\n",
       "      <th>lang</th>\n",
       "      <th>botOrHuman</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>867be96f95dfc4e24541d19c6a5ab8bf</td>\n",
       "      <td>Alex is too nice for love island :(</td>\n",
       "      <td>en</td>\n",
       "      <td>human</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>867be96f95dfc4e24541d19c6a5ab8bf</td>\n",
       "      <td>RT @STVNews: Teenager charged with rape of wom...</td>\n",
       "      <td>en</td>\n",
       "      <td>human</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>867be96f95dfc4e24541d19c6a5ab8bf</td>\n",
       "      <td>@LipsTaco @jennyhastie</td>\n",
       "      <td>en</td>\n",
       "      <td>human</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>867be96f95dfc4e24541d19c6a5ab8bf</td>\n",
       "      <td>@RyanDunbar8 happy bday Ryan have the best day...</td>\n",
       "      <td>en</td>\n",
       "      <td>human</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>867be96f95dfc4e24541d19c6a5ab8bf</td>\n",
       "      <td>@jennyhastie @bootywhispers I just wanna let j...</td>\n",
       "      <td>en</td>\n",
       "      <td>human</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>867be96f95dfc4e24541d19c6a5ab8bf</td>\n",
       "      <td>@bootywhispers @jennyhastie what would u do ?</td>\n",
       "      <td>en</td>\n",
       "      <td>human</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>867be96f95dfc4e24541d19c6a5ab8bf</td>\n",
       "      <td>@Aidsterrr Asking for a mate :/ wee bit line o...</td>\n",
       "      <td>en</td>\n",
       "      <td>human</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>867be96f95dfc4e24541d19c6a5ab8bf</td>\n",
       "      <td>Wonder what a Sunday without the fear feels like</td>\n",
       "      <td>en</td>\n",
       "      <td>human</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>867be96f95dfc4e24541d19c6a5ab8bf</td>\n",
       "      <td>RT @liamfrenchx: Brutal getn wee flashbacks a ...</td>\n",
       "      <td>en</td>\n",
       "      <td>human</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>867be96f95dfc4e24541d19c6a5ab8bf</td>\n",
       "      <td>Went to a&amp;amp;e last night myself after I lock...</td>\n",
       "      <td>en</td>\n",
       "      <td>human</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ID  \\\n",
       "0  867be96f95dfc4e24541d19c6a5ab8bf   \n",
       "1  867be96f95dfc4e24541d19c6a5ab8bf   \n",
       "2  867be96f95dfc4e24541d19c6a5ab8bf   \n",
       "3  867be96f95dfc4e24541d19c6a5ab8bf   \n",
       "4  867be96f95dfc4e24541d19c6a5ab8bf   \n",
       "5  867be96f95dfc4e24541d19c6a5ab8bf   \n",
       "6  867be96f95dfc4e24541d19c6a5ab8bf   \n",
       "7  867be96f95dfc4e24541d19c6a5ab8bf   \n",
       "8  867be96f95dfc4e24541d19c6a5ab8bf   \n",
       "9  867be96f95dfc4e24541d19c6a5ab8bf   \n",
       "\n",
       "                                                data lang botOrHuman     sex  \n",
       "0                Alex is too nice for love island :(   en      human  female  \n",
       "1  RT @STVNews: Teenager charged with rape of wom...   en      human  female  \n",
       "2                             @LipsTaco @jennyhastie   en      human  female  \n",
       "3  @RyanDunbar8 happy bday Ryan have the best day...   en      human  female  \n",
       "4  @jennyhastie @bootywhispers I just wanna let j...   en      human  female  \n",
       "5      @bootywhispers @jennyhastie what would u do ?   en      human  female  \n",
       "6  @Aidsterrr Asking for a mate :/ wee bit line o...   en      human  female  \n",
       "7   Wonder what a Sunday without the fear feels like   en      human  female  \n",
       "8  RT @liamfrenchx: Brutal getn wee flashbacks a ...   en      human  female  \n",
       "9  Went to a&amp;e last night myself after I lock...   en      human  female  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergedEnData.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>data</th>\n",
       "      <th>lang</th>\n",
       "      <th>botOrHuman</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>411900</td>\n",
       "      <td>411900</td>\n",
       "      <td>411900</td>\n",
       "      <td>411900</td>\n",
       "      <td>411900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4119</td>\n",
       "      <td>373808</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>61d95a1f860bc9a7381ae76bf9a798af</td>\n",
       "      <td>wow, it's so sad about MJ :(</td>\n",
       "      <td>en</td>\n",
       "      <td>human</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>100</td>\n",
       "      <td>136</td>\n",
       "      <td>411900</td>\n",
       "      <td>206000</td>\n",
       "      <td>205900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      ID                          data  \\\n",
       "count                             411900                        411900   \n",
       "unique                              4119                        373808   \n",
       "top     61d95a1f860bc9a7381ae76bf9a798af  wow, it's so sad about MJ :(   \n",
       "freq                                 100                           136   \n",
       "\n",
       "          lang botOrHuman     sex  \n",
       "count   411900     411900  411900  \n",
       "unique       1          2       3  \n",
       "top         en      human     bot  \n",
       "freq    411900     206000  205900  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergedEnData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning - CNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4119\n"
     ]
    }
   ],
   "source": [
    "'''Creo la litsa degli ID, delle classi e dei tweets pr ogni ID'''\n",
    "\n",
    "listaIds =[]\n",
    "listaClasses = []\n",
    "matrixTweets = []\n",
    "\n",
    "for index, x in mergedEnData.iterrows():\n",
    "    id = x['ID']\n",
    "    if id not in listaIds:\n",
    "        newList = list()\n",
    "        newList.append(x[1])\n",
    "        matrixTweets.append(newList)\n",
    "        listaIds.append(id)\n",
    "        listaClasses.append(x[3])\n",
    "    else:\n",
    "        ls = matrixTweets[listaIds.index(id)]\n",
    "        ls.append(x[1])\n",
    "        matrixTweets[listaIds.index(id)] = ls\n",
    "        \n",
    "print(len(listaIds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Trasformo le entità, lascio le faccine, levo le stopword e se serve agli embeddings lemmatizzo'''\n",
    "dataEn = None\n",
    "target= None\n",
    "df = None\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install ekphrasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n"
     ]
    }
   ],
   "source": [
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "\n",
    "text_processor = TextPreProcessor (\n",
    "    # terms that will be normalized\n",
    "    normalize=[ 'email' , 'percent' , 'money' , 'phone' ,\n",
    "                'time' , 'url' , 'date' , 'number' ] ,\n",
    "    fix_html=True ,  # fix HTML tokens\n",
    "    segmenter=\"twitter\" ,\n",
    "    corrector=\"twitter\" ,\n",
    "    unpack_hashtags=True ,  # perform word segmentation on hashtags\n",
    "    unpack_contractions=True ,  # Unpack contractions (can't -> can not)\n",
    "    spell_correct_elong=True ,  # spell correction for elongated words\n",
    "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "    dicts=[ emoticons ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Transform sentences to word embeddings'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Transform sentences to word embeddings'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_300 = gensim.models.KeyedVectors.load_word2vec_format(\"/Volumes/MacPassport/PycharmProjects/crawl-300d-2M-subword/crawl-300d-2M-subword.vec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Trasformo le frasi'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Trasformo le frasi'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import TweetTokenizer as TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import random as rn\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "i = 0\n",
    "matrixTweetsEmb = np.zeros ( (len(matrixTweets) ,100, 50, 300) )\n",
    "for tweetsUser in matrixTweets:\n",
    "    \n",
    "    embTweetsUser = []\n",
    "    if(i % 100) == 0:\n",
    "         print(i)\n",
    "    for tweet in tweetsUser:\n",
    "        embTweetUser = np.zeros([50,300])\n",
    "        #Preprocesso\n",
    "        tokList = text_processor.pre_process_doc(tweet)\n",
    "        #Rimuovo le stopwords\n",
    "        tokList = [w for w in tokList if not w in stop_words]\n",
    "        #trovo l'embedding\n",
    "        numTok = 0;\n",
    "        for token in tokList[0:50]:\n",
    "            g_vec =[]\n",
    "            is_in_model = False\n",
    "            if token in google_300.vocab.keys ( ):\n",
    "                is_in_model = True\n",
    "                g_vec = google_300.word_vec(token)\n",
    "            elif token == \"<number>\":\n",
    "                is_in_model = True\n",
    "                g_vec = google_300.word_vec( \"number\")\n",
    "            elif token == \"<percent>\":\n",
    "                is_in_model = True\n",
    "                g_vec = google_300.word_vec(\"percent\")\n",
    "            elif token == \"<money>\":\n",
    "                is_in_model = True\n",
    "                g_vec = google_300.word_vec(\"money\")\n",
    "            elif token == \"<email>\":\n",
    "                is_in_model = True\n",
    "                g_vec = google_300.word_vec(\"email\")\n",
    "            elif token == \"<phone>\":\n",
    "                is_in_model = True\n",
    "                g_vec = google_300.word_vec(\"phone\")\n",
    "            elif token == \"<time>\":\n",
    "                is_in_model = True\n",
    "                g_vec = google_300.word_vec(\"time\")\n",
    "            elif token == \"<date>\":\n",
    "                is_in_model = True\n",
    "                g_vec = google_300.word_vec(\"date\")\n",
    "            elif token == \"<url>\":\n",
    "                is_in_model = True\n",
    "                g_vec = google_300.word_vec(\"url\")\n",
    "            elif not is_in_model:\n",
    "                max = len ( google_300.vocab.keys ( ) ) - 1\n",
    "                index = rn.randint ( 0 , max )\n",
    "                word = google_300.index2word[ index ]\n",
    "                g_vec = google_300.word_vec( word )\n",
    "\n",
    "            embTweetUser[numTok] = np.array(g_vec)\n",
    "            numTok += 1\n",
    "        embTweetsUser.append(np.array(embTweetUser))\n",
    "        embTweetUser = None\n",
    "    matrixTweetsEmb[i] =np.array(embTweetsUser)\n",
    "    i +=1\n",
    "    embTweetsUser = None\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4119, 100, 50, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Num Utenti x Num Tweets x Num MaxTokens x Dim Embedding'''\n",
    "#import numpy as np \n",
    "#matrixTweetsEmb = np.array(matrixTweetsEmb)\n",
    "\n",
    "\n",
    "matrixTweets = None\n",
    "print(matrixTweetsEmb.shape)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!{sys.executable} -m pip install joblib\n",
    "import joblib\n",
    "joblib.dump(matrixTweetsEmb,'/Volumes/MacPassport/PycharmProjects/BOToRNOT/matrixTweetsEmb_FAST.dump')\n",
    "#matrixTweetsEmb = joblib.load('matrixTweetsEmb_4177_100_50_300.dump')\n",
    "joblib.dump(listaClasses,'/Volumes/MacPassport/PycharmProjects/BOToRNOT/listaClasses.dump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 96, 46, 200)       1500200   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 23, 200)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 44, 20, 100)       400100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 10, 100)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 8, 20)         18020     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 4, 20)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 400)               320400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               80200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 2,339,222\n",
      "Trainable params: 2,339,222\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "model.add(Conv2D(200,(5,5), activation ='relu', input_shape=(100,50,300)))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Conv2D(100,(5,4), activation ='relu'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Conv2D(20,(3,3), activation ='relu'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(400, activation=\"tanh\"))\n",
    "model.add(Dense(200, activation=\"tanh\"))\n",
    "model.add(Dense(100, activation=\"tanh\"))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'col': 0, 'mapping': [('human', 1), ('bot', 2)]}]\n"
     ]
    }
   ],
   "source": [
    "#!{sys.executable} -m pip install category_encoders\n",
    "import category_encoders as ce\n",
    "le =  ce.OneHotEncoder(return_df=False, impute_missing=False, handle_unknown=\"ignore\")\n",
    "training_classes = le.fit_transform(listaClasses)\n",
    "print(le.category_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3295 samples, validate on 824 samples\n",
      "Epoch 1/15\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "for i in range(0,10):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(200,(5,5), activation ='relu', input_shape=(100,50,300)))\n",
    "    model.add(MaxPool2D(2,2))\n",
    "    model.add(Conv2D(100,(5,4), activation ='relu'))\n",
    "    model.add(MaxPool2D(2,2))\n",
    "    model.add(Conv2D(20,(3,3), activation ='relu'))\n",
    "    model.add(MaxPool2D(2,2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(400, activation=\"tanh\"))\n",
    "    model.add(Dense(200, activation=\"tanh\"))\n",
    "    model.add(Dense(100, activation=\"tanh\"))\n",
    "    model.add(Dense(2, activation=\"softmax\"))\n",
    "    model.compile ( loss='categorical_crossentropy' , optimizer='adam' , metrics=['accuracy'] )\n",
    "\n",
    "    from keras.callbacks import ModelCheckpoint\n",
    "    filepath=\"/Volumes/MacPassport/PycharmProjects/botOrNot/MAY.weights.{epoch:05d}-{val_loss:.5f}-{val_acc:.5f}_FASTTEXT\"+str(i)+\".hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    history = model.fit(matrixTweetsEmb,training_classes,64,15,\n",
    "                          validation_split= 0.20 ,\n",
    "                          callbacks=callbacks_list,\n",
    "                          verbose=1)\n",
    "    history=None\n",
    "    model=None\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(history.history.keys())\n",
    "%matplotlib qt\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('02.CNN_100x50x300D_google_0.9693.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(matrixTweetsEmb,listaClasses, test_size=0.10, random_state=891)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.metrics  import classification_report\n",
    "from keras.callbacks import Callback\n",
    "class MyCallBack(Callback):\n",
    "    def __init__(self,verbose=0):\n",
    "\n",
    "        super(Callback, self).__init__()\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get('val_loss')\n",
    "        # if current < 0.014:\n",
    "        #     self.model.stop_training = True\n",
    "\n",
    "        predicted = model.predict ( X_test )\n",
    "\n",
    "        test = [ '0' ] * len ( X_test )\n",
    "        i = 0\n",
    "        for cl in predicted:\n",
    "            test[ i ] = str ( np.argmax ( cl ) )\n",
    "            i += 1\n",
    "\n",
    "        test_lab = [ '0' ] * len ( X_test )\n",
    "        i = 0\n",
    "        for cl in y_test:\n",
    "            test_lab[ i ] = str ( np.argmax ( cl ) )\n",
    "            i += 1\n",
    "\n",
    "        print ( len ( X_test ) )\n",
    "        print ( classification_report ( test , test_lab, digits=5 ) )\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile ( loss='categorical_crossentropy' , optimizer='adam' , metrics=['accuracy'] )\n",
    "\n",
    "history = model.fit(X_train,y_train,batch_size=32,epochs=7,\n",
    "                      validation_data= (X_test,y_test) ,\n",
    "                      callbacks=callbacks_list,\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "test = ['0']* len(X_test)\n",
    "i= 0\n",
    "for cl in predicted:\n",
    "    test[i] = str(np.argmax (cl))\n",
    "    i +=1\n",
    "\n",
    "test_lab = ['0']* len(X_test)\n",
    "i= 0\n",
    "for cl in y_test:\n",
    "    test_lab[ i ] = str(np.argmax ( cl ))\n",
    "    i += 1\n",
    "\n",
    "\n",
    "print(len(X_test))\n",
    "acc = accuracy_score(test, test_lab)\n",
    "print(\" Accuracy:\", acc)\n",
    "\n",
    "print(classification_report(test,test_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(matrixTweetsEmb,training_classes, test_size=0.10, random_state=891)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixTweetsEmb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"/Volumes/MacPassport/PycharmProjects/botOrNot/MAY.weights.{epoch:02d}-{val_loss:.5f}_FASTTEXT.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    checkpoint,\n",
    "    #MyCallBack(verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=7654).split(X_train,ytt))\n",
    "X_tr = []\n",
    "y_tr = []\n",
    "X_te = []\n",
    "y_te = []\n",
    "for j , (train_idx , val_idx) in enumerate ( folds ):\n",
    "    print ( '\\nFold ' , j )\n",
    "    X_tr = X_train[ train_idx ]\n",
    "    y_tr = y_train[ train_idx ]\n",
    "    X_te = X_train[ val_idx ]\n",
    "    y_te = y_train[ val_idx ]\n",
    "    y_tr = ce.transform(y_tr)\n",
    "    y_te = ce.transform(y_te)\n",
    "    model.fit(X_tr,y_tr,64,15,\n",
    "                          validation_data= (X_te,y_te) ,\n",
    "                          callbacks=callbacks_list,\n",
    "                          verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le.category_mapping[0]['mapping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytt = []\n",
    "for i in y_train:\n",
    "    if np.argmax(i) == 0:\n",
    "        cl = 'human'\n",
    "        ytt.append(cl)\n",
    "    else:\n",
    "        cl = 'bot'\n",
    "        ytt.append(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = le.transform(y_test)\n",
    "y_train = le.transform(y_train)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1.0,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
